{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import MySQLdb as mariadb\n",
    "from astropy.io import ascii\n",
    "import numpy as np\n",
    "import SEFD_estimator\n",
    "import scipy.optimize\n",
    "from astropy.table import vstack\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "#dirname = os.path.dirname(__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRelevantSections(all_corr_sections):\n",
    "    relevant_tags = ['STATION', 'DROP', 'MANUAL', 'SNR']\n",
    "    relevant_sections = []\n",
    "    for tag in relevant_tags:\n",
    "        for section in all_corr_sections:\n",
    "            if tag in section[0:15]:\n",
    "                relevant_sections.append(section)\n",
    "    return relevant_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droppedChannels(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    dropped_chans = []\n",
    "    for ant in station_id[1]:\n",
    "        regex = ant + '.*'\n",
    "        dropped = re.findall(regex,text_section,re.MULTILINE)\n",
    "        if dropped == []:\n",
    "            dropped_chans.append('')            \n",
    "        elif len(dropped[0]) < 4:\n",
    "            dropped_chans.append('')\n",
    "        else:\n",
    "            dropped_chans.append(','.join(dropped))\n",
    "    return dropped_chans  \n",
    "    # This function takes a block of text, and scrapes out whether any AuScope antennas have dropped channels\n",
    "    # The input of this function is a text section from the correlator report (section[5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualPcal(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    manual_pcal = []\n",
    "    for ant in station_id[1]:\n",
    "        if ant in text_section:\n",
    "            manual_pcal.append(True)\n",
    "        else:\n",
    "            manual_pcal.append(False)\n",
    "    return manual_pcal\n",
    "    # this determines whether manual pcal happened for any of our telescopes.\n",
    "    # The input of this function is a text section from the correlator report (section[6])\n",
    "    \n",
    "def sefdTableExtract(text_section, antennas_corr_reference, antenna_reference):\n",
    "    if len(text_section) > 20:\n",
    "        # old corr files have an extra bit in the SNR table section we want removed\n",
    "        regex = \"CONTROL.*\" #this may cause some issues\n",
    "        has_control = re.findall(regex,text_section,re.MULTILINE)\n",
    "        if len(has_control) > 0:\n",
    "            text_section = text_section.split(\"CONTROL\")[0]\n",
    "        col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "        snr_data = ascii.read(text_section, data_start=4, fast_reader=True, names=col_names)\n",
    "        # Make sure antennas being extracted exist in both the corr-file and skd-file\n",
    "        mask = np.isin(np.asarray(antennas_corr_reference)[:,0], np.asarray(antenna_reference)[:,1])\n",
    "        # This next loop applies the restriction above, along with removing random symbols (like 1s).\n",
    "        bad_bl_mask = []\n",
    "        for i in range(0,len(snr_data['bl'])):\n",
    "            bl = snr_data['bl'][i]\n",
    "            if bl[0] not in list(np.asarray(antennas_corr_reference)[mask,1]) or bl[1] not in list(np.asarray(antennas_corr_reference)[mask,1]):\n",
    "                bad_bl_mask.append(i)\n",
    "        snr_data.remove_rows(bad_bl_mask)\n",
    "        table_array = np.array([snr_data['X_snr'],snr_data['X_n'],snr_data['S_snr'],snr_data['S_n']])\n",
    "        # Need to manipulate the array so it is the same as the table, can probably create the array more elegantly.\n",
    "        corrtab = np.fliplr(np.rot90(table_array, k=1, axes=(1,0)))\n",
    "        corrtab_split = np.hsplit(corrtab,2)\n",
    "        corrtab_X = corrtab_split[0]\n",
    "        corrtab_S = corrtab_split[1]\n",
    "    else:\n",
    "        print(\"No SNR table available!\")\n",
    "        snr_data = []\n",
    "        corrtab_X = []\n",
    "        corrtab_S = []\n",
    "        # if snr table isnt included for some reason, this stops the script from crashing.\n",
    "        # Instead SEFD estimation will be skipped.\n",
    "    return snr_data, corrtab_X, corrtab_S\n",
    "\n",
    "    \n",
    "def antennaReference_CORR(text_section):\n",
    "    regex = '\\(.{4}\\)'\n",
    "    antennas_corr_report = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antennas_corr_reference = []\n",
    "    for line in antennas_corr_report:\n",
    "        if '/' in line:\n",
    "            ref = [line[1:3],line[4]]\n",
    "            antennas_corr_reference.append(ref)\n",
    "        elif '-' in line: # this is to handle some funky corr report styles.\n",
    "            ref = [line[3:5], line[1]]\n",
    "            antennas_corr_reference.append(ref)\n",
    "    return antennas_corr_reference\n",
    "    # This function takes the section[4] of the corr report and gives the 2 character\n",
    "    # station code plus the single character corr code.\n",
    "    \n",
    "def antennaReference_SKD(text_section):\n",
    "    regex = \"^A\\s\\s.*\"\n",
    "    alias_reference = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antenna_reference = []\n",
    "    for entry in alias_reference:\n",
    "        entry = entry.split()\n",
    "        ref = [entry[2], entry[14], entry[15]]\n",
    "        antenna_reference.append(ref)\n",
    "    return antenna_reference\n",
    "\n",
    "def predictedSEFDextract(text_section, antenna_reference):\n",
    "    regex_sefd = \"^T\\s.*\" #this may cause some issues\n",
    "    sefd_skd = re.findall(regex_sefd,text_section,re.MULTILINE)\n",
    "    stations_SEFD =[]\n",
    "    for line in sefd_skd:\n",
    "        line = line.split()\n",
    "        for i in range(0, len(antenna_reference)):\n",
    "            if line[1] == antenna_reference[i][2] or line[2] == antenna_reference[i][0]:\n",
    "                SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "                stations_SEFD.append(SEFD_X_S)\n",
    "    SEFD_tags = np.asarray(stations_SEFD)[:,0]\n",
    "    SEFD_X = np.asarray(stations_SEFD)[:,1].astype(np.float)\n",
    "    SEFD_S = np.asarray(stations_SEFD)[:,2].astype(np.float)\n",
    "    return SEFD_tags, SEFD_X, SEFD_S\n",
    "    # This block of code grabs all the SEFD setting lines and pulls the X and S SEFD for each station.\n",
    "    \n",
    "def basnumArray(snr_data, antennas_corr_reference, SEFD_tags):\n",
    "    basnum = []\n",
    "    for bl in snr_data['bl']:\n",
    "        bl_pair = []\n",
    "        for i in range(0, len(antennas_corr_reference)):\n",
    "            if antennas_corr_reference[i][1] in bl:\n",
    "                index = np.where(SEFD_tags == antennas_corr_reference[i][0])\n",
    "                bl_pair.append(index[0])\n",
    "        basnum.append(np.concatenate(bl_pair))\n",
    "    basnum=np.stack(basnum, axis=0)\n",
    "    return basnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning corr and skd file ingest for experiment r1952.\n",
      "Calculating SEFD values for experiment r1952.\n",
      "[33303.6592969    627.16861745  7983.70054855  2656.77606763\n",
      "  3208.13930016  2935.75044588  1932.97321975  3780.8067785\n",
      "  1814.50795422  1331.73387162   339.2908582    622.57841667\n",
      "   359.50798325]\n",
      "[20381.15465371   374.26614948  3768.36828019  1279.12715881\n",
      "  2327.23471776   859.73001266  3817.69880955  1864.76779845\n",
      "  1787.61271298  1970.87354681   416.48334599  1101.60950117\n",
      "   795.45501405]\n"
     ]
    }
   ],
   "source": [
    "exp_id = 'r1952'\n",
    "db_name = 'auscope_db_test'\n",
    "\n",
    "if os.path.isfile(\"corr_files/\"+ exp_id + '.corr'):\n",
    "    print(\"Beginning corr and skd file ingest for experiment \" + exp_id + \".\")\n",
    "    with open('corr_files/'+ str(exp_id) + '.corr') as file:\n",
    "        contents = file.read()\n",
    "        corr_section = contents.split('\\n+')\n",
    "        if len(corr_section) < 3: # another ad-hoc addition for if corr-reports have a space before ever line in them (e.g. aov032)\n",
    "            corr_section = contents.split('\\n +')\n",
    "    relevant_section = extractRelevantSections(corr_section)\n",
    "    if len(relevant_section) < 4:\n",
    "        print(\"Incompatible correlator report format.\")\n",
    "    station_id = [\"Ke\", \"Yg\", \"Hb\", \"Ho\"]\n",
    "    # check which stations participated in experiment (needed for cases where we cant calculate SEFD)\n",
    "    valid_stations = []\n",
    "    for j in range(0, len(station_id)):\n",
    "        if station_id[j] + \"/\" in relevant_section[0]:\n",
    "            valid_stations.append(station_id[j])\n",
    "    # Extract manual pcal and dropped channels for all telescopes first\n",
    "    dropped_channels = droppedChannels(relevant_section[1])\n",
    "    manual_pcal = manualPcal(relevant_section[2])\n",
    "    # Now to extract what we need to calculate the SEFDs\n",
    "    if os.path.isfile('skd_files/' + str(exp_id) + '.skd'):\n",
    "        with open('skd_files/' + str(exp_id) + '.skd') as file:\n",
    "            skd_contents = file.read()\n",
    "        antennas_corr_reference = antennaReference_CORR(relevant_section[0])\n",
    "        if len(antennas_corr_reference) == 0:\n",
    "            print(\"No stations defined in correlator report!\")\n",
    "        antenna_reference = antennaReference_SKD(skd_contents)\n",
    "        snr_data, corrtab_X, corrtab_S = sefdTableExtract(relevant_section[3], antennas_corr_reference, antenna_reference)\n",
    "        if len(snr_data) == 0: # this is if corr file exists, but no SNR table exists.\n",
    "            print(\"No SNR table exists!\")\n",
    "            SEFD_tags = np.array(valid_stations)\n",
    "            X = [None, None, None, None]\n",
    "            S = [None, None, None, None]\n",
    "        else:\n",
    "            SEFD_tags, SEFD_X, SEFD_S = predictedSEFDextract(skd_contents, antenna_reference)\n",
    "            basnum = basnumArray(snr_data, antennas_corr_reference, SEFD_tags)\n",
    "            print(\"Calculating SEFD values for experiment \" + exp_id + \".\")\n",
    "            X = SEFD_estimator.main(SEFD_X, corrtab_X, basnum)\n",
    "            S = SEFD_estimator.main(SEFD_S, corrtab_S, basnum)\n",
    "            if len(X) == 1 or len(S) == 1: # for the rare case when less than 3 stations are in the experiment with valid data.\n",
    "                SEFD_tags = np.array(valid_stations)\n",
    "                X = [None, None, None, None]\n",
    "                S = [None, None, None, None]\n",
    "            else:\n",
    "                X = [round(num, 1) for num in X]\n",
    "                S = [round(num, 1) for num in S]\n",
    "    else:\n",
    "        print(\"No SKD file available\")\n",
    "        SEFD_tags = np.array(valid_stations)\n",
    "        X = [None, None, None, None]\n",
    "        S = [None, None, None, None]\n",
    "\n",
    "    # fix for when station is in corr notes, but does not observe. \n",
    "    # Below code creates list of station codes that exist in the valid station.\n",
    "    stations_to_add = list(set(SEFD_tags).intersection(valid_stations))\n",
    "\n",
    "    # add to database\n",
    "    for i in range(0,len(stations_to_add)):\n",
    "        sql_station = \"\"\"\n",
    "            UPDATE {}\n",
    "            SET estSEFD_X=%s, estSEFD_S=%s, Manual_Pcal=%s, Dropped_Chans=%s\n",
    "            WHERE ExpID=%s\n",
    "        \"\"\".format(stations_to_add[i])\n",
    "        data = [X[list(SEFD_tags).index(stations_to_add[i])], S[list(SEFD_tags).index(stations_to_add[i])], manual_pcal[i], dropped_channels[i], str(exp_id)]\n",
    "        conn = mariadb.connect(user='auscope', passwd='password', db=str(db_name))\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_station, data)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        with open(stations_to_add[i] + '_corr_reports.csv','a') as f:\n",
    "            with open(stations_to_add[i] + '_corr_reports.csv','r') as f_read:\n",
    "                if str(exp_id) in f_read.read():\n",
    "                    break\n",
    "                else:                                   \n",
    "                    station_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    station_writer.writerow(data)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ho']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
